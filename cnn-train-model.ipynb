{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Image Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data to a trainable structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import models, layers\n",
    "batchSize = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15081 images belonging to 6 classes.\n",
      "Found 5432 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "    rescale= 1/255.0,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range= 0.1,\n",
    "    rotation_range=10.0,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    "    )\n",
    "train_data = train_generator.flow_from_directory(\n",
    "        directory='images/train/',\n",
    "        color_mode='grayscale',\n",
    "        target_size=(300,300),\n",
    "        batch_size=batchSize,\n",
    "        class_mode='categorical',\n",
    "        classes=['0','1','2','3','4','5']\n",
    "    )\n",
    "test_generator = ImageDataGenerator(rescale=1/255.0)\n",
    "test_data = test_generator.flow_from_directory(\n",
    "                directory='images/test/',\n",
    "                color_mode='grayscale',\n",
    "                target_size=(300,300),\n",
    "                batch_size= batchSize,\n",
    "                class_mode= 'categorical',\n",
    "                classes=['0','1','2','3','4','5']                                \n",
    "            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying CNN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model : AlexNet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = models.Sequential()\n",
    "model1.add(layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation= 'relu', input_shape=(300, 300, 1)))\n",
    "model1.add(layers.MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "model1.add(layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu'))\n",
    "model1.add(layers.MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "model1.add(layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
    "model1.add(layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
    "model1.add(layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu'))\n",
    "model1.add(layers.MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n",
    "model1.add(layers.Flatten())\n",
    "model1.add(layers.Dense(568, activation='relu'))\n",
    "model1.add(layers.Dropout(0.2))\n",
    "model1.add(layers.Dense(6, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 73, 73, 96)        11712     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 36, 36, 96)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 256)       614656    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 15, 15, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 13, 13, 384)       885120    \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 11, 11, 384)       1327488   \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 9, 9, 256)         884992    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 568)               2327096   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 568)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 3414      \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Total params: 6054478 (23.10 MB)\n",
      "Trainable params: 6054478 (23.10 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "118/118 [==============================] - 561s 5s/step - loss: 1.2583 - accuracy: 0.4449 - val_loss: 0.6016 - val_accuracy: 0.7064\n",
      "Epoch 2/10\n",
      "118/118 [==============================] - 367s 3s/step - loss: 0.4192 - accuracy: 0.8279 - val_loss: 0.1264 - val_accuracy: 0.9543\n",
      "Epoch 3/10\n",
      "118/118 [==============================] - 370s 3s/step - loss: 0.1191 - accuracy: 0.9572 - val_loss: 0.0620 - val_accuracy: 0.9733\n",
      "Epoch 4/10\n",
      "118/118 [==============================] - 371s 3s/step - loss: 0.1897 - accuracy: 0.9385 - val_loss: 0.1008 - val_accuracy: 0.9689\n",
      "Epoch 5/10\n",
      "118/118 [==============================] - 373s 3s/step - loss: 0.0365 - accuracy: 0.9884 - val_loss: 0.0286 - val_accuracy: 0.9901\n",
      "Epoch 6/10\n",
      "118/118 [==============================] - 372s 3s/step - loss: 0.0230 - accuracy: 0.9925 - val_loss: 0.1206 - val_accuracy: 0.9722\n",
      "Epoch 7/10\n",
      "118/118 [==============================] - 372s 3s/step - loss: 0.0249 - accuracy: 0.9911 - val_loss: 0.1387 - val_accuracy: 0.9728\n",
      "Epoch 8/10\n",
      "118/118 [==============================] - 373s 3s/step - loss: 0.0193 - accuracy: 0.9931 - val_loss: 0.1723 - val_accuracy: 0.9562\n",
      "Epoch 9/10\n",
      "118/118 [==============================] - 375s 3s/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 0.0092 - val_accuracy: 0.9963\n",
      "Epoch 10/10\n",
      "118/118 [==============================] - 373s 3s/step - loss: 0.0294 - accuracy: 0.9907 - val_loss: 0.0996 - val_accuracy: 0.9779\n"
     ]
    }
   ],
   "source": [
    "training = model1.fit( train_data, epochs=10, shuffle=True, validation_data=test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save(\"CNN_model_extended.keras\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
